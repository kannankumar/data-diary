{
  
    
        "post0": {
            "title": "Tracking GPU Memory Usage",
            "content": "The most amazing thing about Collaboratory (or Google&#39;s generousity) is that there&#39;s also GPU option available. . In this short notebook we look at how to track GPU memory usage. . This notebook has been divided into sections. Feel free to skip the sections which you are already familar with. . . Footnote: This notebook is a fork of a great Colab notebook and it is edited for my personal reference. . Enabling GPU (on Colab) . If you are using a Colab environment and have not tried switching to the GPU mode on the Colab notebook before, here&#39;s a quick refresher on that. . When using another notebook/environment you will need to find out how to connect to a GPU runtime on your own. . Sorry, I haven&#39;t perfected my environment-sensing and mind-reading skills yet. . Follow on the collaboratory menu tabs, &quot;Runtime&quot; =&gt; &quot;Change runtime type&quot;. . Choosing Runtime type . Then you should see a pop-up where you can choose GPU. . After you change your runtime, your runtime should automatically restart (which means information from executed cells disappear). . Checking Runtime type . A quick way to check your current runtime is to hover on the toolbar where it shows the RAM and Disk details. If it mentions &quot;(GPU)&quot;, then the Colab notebook is connected to a GPU runtime. Otherwise a standard CPU runtime. . . Checking GPU availability . To find out if GPU is available, we have two preferred ways: . PyTorch / Tensorflow APIs (Framework interface) Every deep learning framework has an API to check the details of the available GPU devices. . | Nvidia SMI (Command line interface) Nvidia is the manufacturer of the GPUs currently used for Deep Learning. Nvidia provides a command line tool for their System Management Interface(nvidia-smi for short) . | pytorch . import torch torch.cuda.is_available() . True . nvidia-smi . If you own GPU you may be familiar with nvidia-smi, NVIDIA binary to print out gpu&#39;s utilization summary. . nvidia-smi is now available by default in the colab environment. Running nvidia-smi gives the details of the connected GPU runtime. . !nvidia-smi . Sun Apr 19 17:59:57 2020 +--+ | NVIDIA-SMI 440.64.00 Driver Version: 418.67 CUDA Version: 10.1 | |-+-+-+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 Tesla P100-PCIE... Off | 00000000:00:04.0 Off | 0 | | N/A 32C P0 26W / 250W | 10MiB / 16280MiB | 0% Default | +-+-+-+ +--+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | No running processes found | +--+ . Violla! I got Tesla P100 GPU w/ 16 GB memory. This could be different for you. On Google Colab you might get a Tesla K80 GPU with 12 GB memory too. . Now if you want to acquire values in this summary text, youl probably want something else like gputi. . Next section demonstrates how. . Fetching GPU usage stats in code . To find out if GPU is available, we have again multiple ways. I have two preferred ways based on whether I&#39;m working with a DL framework or writing things from scratch. Here they are: . PyTorch / Tensorflow APIs (Framework interface) Every deep learning framework has an API to monitor the stats of the GPU devices. It is easier to use this if working with a DL framework. . | USing GPUtil python packages (Custom function) A few python packages like gputil provide a interface to fetch GPU usage statistics. This can be used if you are not working with any DL framework. . | 1. Pytorch CUDA APIs . import torch # setting device on GPU if available, else CPU device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) print(&#39;Using device:&#39;, device) print() #Additional Info when using cuda if device.type == &#39;cuda&#39;: print(torch.cuda.get_device_name(0)) print(&#39;Memory Usage:&#39;) print(&#39;Allocated:&#39;, round(torch.cuda.memory_allocated(0)/1024**3,1), &#39;GB&#39;) print(&#39;Cached: &#39;, round(torch.cuda.memory_cached(0)/1024**3,1), &#39;GB&#39;) . Using device: cuda Tesla P100-PCIE-16GB Memory Usage: Allocated: 0.0 GB Cached: 0.0 GB . 2. Using GPUtil python package . Let&#39;s start by installing a few packages needed to print out our process memory usage... . !pip install gputil !pip install psutil !pip install humanize . Collecting gputil Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz Building wheels for collected packages: gputil Building wheel for gputil (setup.py) ... done Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=52a9da8425c2b31a65708cba7214a056bc17e9d99dc55b740d130f0d4ee71c32 Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd Successfully built gputil Installing collected packages: gputil Successfully installed gputil-1.4.0 Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8) Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1) . Now gputil, psutil, and humanize are all available. . mem_report helper function . Here&#39;s a simple function to print out memory usage on both CPU and GPU. . # Import packages import os,sys,humanize,psutil,GPUtil # Define function def mem_report(): print(&quot;CPU RAM Free: &quot; + humanize.naturalsize( psutil.virtual_memory().available )) GPUs = GPUtil.getGPUs() for i, gpu in enumerate(GPUs): print(&#39;GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%&#39;.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100)) # Execute function # mem_report() . Trying it out . To test the usage of GPU memory using the above function, lets do the following: . Download a pretrained model from the pytorch model library and transfer it to the Cuda GPU. | Then we can run the mem_report() helper function to check the used/available GPU statistics. | . import torchvision.models as models wide_resnet50_2 = models.wide_resnet50_2(pretrained=True) if torch.cuda.is_available(): resnet18.cuda() mem_report() . CPU RAM Free: 11.5 GB GPU 0 ... Mem Free: 11058MB / 11441MB | Utilization 3% . Closing words . Now you can use any of the above methods anywhere you want the GPU Memory Usage from. . I typically use it from while training a Deep Learning model within the training loop. This helps me to get a sense of how much of the GPU memory is available/unused by me. Based on that I can increase/decrease the batch size to utilize the GPU resources efficiently. .",
            "url": "https://kannankumar.github.io/data-diary/jupyter/deep-learning/2020/04/22/Tracking_GPU_Memory_Usage.html",
            "relUrl": "/jupyter/deep-learning/2020/04/22/Tracking_GPU_Memory_Usage.html",
            "date": " • Apr 22, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": ". About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](nb_assets/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://kannankumar.github.io/data-diary/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://kannankumar.github.io/data-diary/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://kannankumar.github.io/data-diary/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://kannankumar.github.io/data-diary/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}